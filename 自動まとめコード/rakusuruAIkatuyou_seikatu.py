# ----------------------------------------------------------------
# ã¾ã¨ã‚ã‚µã‚¤ãƒˆè‡ªå‹•ç”Ÿæˆãƒ—ãƒ­ã‚°ãƒ©ãƒ 
# ----------------------------------------------------------------

# 1. å¿…è¦ãªãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’èª­ã¿è¾¼ã‚€
import requests
from bs4 import BeautifulSoup
from duckduckgo_search import DDGS
import time

# ----------------------------------------------------------------
# 2. è¨­å®šé …ç›®ï¼ˆã“ã“ã‚’è‡ªç”±ã«å¤‰æ›´ã—ã¦ãã ã•ã„ï¼‰
# ----------------------------------------------------------------

# â˜…æ¤œç´¢ã—ãŸã„ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’æŒ‡å®š
SEARCH_KEYWORD = "ç”Ÿæ´»ãŒæ¥½ã«ãªã‚‹ AIæ´»ç”¨ å®¶äº‹"

# â˜…æ¤œç´¢ã—ã¦æƒ…å ±ã‚’é›†ã‚ã‚‹ã‚µã‚¤ãƒˆã®æ•°
NUM_SITES_TO_CHECK = 10

# â˜…ç”Ÿæˆã•ã‚Œã‚‹HTMLãƒ•ã‚¡ã‚¤ãƒ«å
OUTPUT_FILENAME = "ç”Ÿæ´»AIæ´»ç”¨ã¾ã¨ã‚.html"

# â˜…å„ã‚µã‚¤ãƒˆã‹ã‚‰æŠ½å‡ºã™ã‚‹æœ¬æ–‡ã®æœ€å¤§æ–‡å­—æ•°
MAX_TEXT_LENGTH = 150

# ----------------------------------------------------------------
# ã“ã“ã‹ã‚‰ä¸‹ã®ã‚³ãƒ¼ãƒ‰ã¯å¤‰æ›´ä¸è¦ã§ã™
# ----------------------------------------------------------------

def search_web(keyword, max_results):
    """æŒ‡å®šã•ã‚ŒãŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§Webæ¤œç´¢ã—ã€URLã®ãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    print(f"ã€Œ{keyword}ã€ã§Webæ¤œç´¢ã‚’é–‹å§‹ã—ã¾ã™...")
    results = []
    try:
        with DDGS() as ddgs:
            for r in ddgs.text(keyword, region='jp-jp', max_results=max_results):
                results.append(r)
        print(f"{len(results)}ä»¶ã®æ¤œç´¢çµæœã‚’å–å¾—ã—ã¾ã—ãŸã€‚")
        return [r['href'] for r in results]
    except Exception as e:
        print(f"æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return []

def scrape_content(url):
    """æŒ‡å®šã•ã‚ŒãŸURLã‹ã‚‰ã‚¿ã‚¤ãƒˆãƒ«ã¨æœ¬æ–‡ã®è¦ç‚¹ã‚’æŠ½å‡ºã™ã‚‹"""
    print(f"-> {url} ã‹ã‚‰æƒ…å ±ã‚’æŠ½å‡ºä¸­...")
    try:
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}
        response = requests.get(url, headers=headers, timeout=10)
        response.raise_for_status()
        response.encoding = response.apparent_encoding
        soup = BeautifulSoup(response.text, 'html.parser')
        title = soup.find('title').text if soup.find('title') else "ã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜"
        paragraphs = soup.find_all('p')
        content_text = ""
        for p in paragraphs:
            content_text += p.get_text().strip()
            if len(content_text) > MAX_TEXT_LENGTH:
                break
        if len(content_text) < 50:
             content_text = ' '.join(soup.body.get_text().split())
        summary = content_text[:MAX_TEXT_LENGTH] + "..." if len(content_text) > MAX_TEXT_LENGTH else content_text
        if not summary:
            return None
        return {'title': title.strip(), 'summary': summary.strip(), 'url': url}
    except Exception as e:
        print(f"  (ã‚¨ãƒ©ãƒ¼: {url} ã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ - {e})")
        return None

def create_html(keyword, site_data_list):
    """æŠ½å‡ºã—ãŸãƒ‡ãƒ¼ã‚¿ã‹ã‚‰HTMLã‚’ç”Ÿæˆã™ã‚‹"""
    print("HTMLãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™...")
    cards_html = ""
    for data in site_data_list:
        cards_html += f"""
        <div class="card">
            <h2><a href="{data['url']}" target="_blank">{data['title']}</a></h2>
            <p>{data['summary']}</p>
            <a href="{data['url']}" target="_blank" class="source-link">ç¶šãã‚’èª­ã‚€</a>
        </div>
        """
    html_template = f"""
<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>{keyword} ã®ã¾ã¨ã‚</title>
    <style>
        body {{ font-family: 'Segoe UI', Meiryo, system-ui, sans-serif; background-color: #f4f7f6; color: #333; margin: 0; padding: 20px; }}
        .container {{ max-width: 800px; margin: 0 auto; }}
        header h1 {{ color: #2c3e50; border-bottom: 3px solid #3498db; padding-bottom: 10px; }}
        .card {{ background-color: #ffffff; border-radius: 8px; box-shadow: 0 4px 8px rgba(0,0,0,0.1); margin-bottom: 20px; padding: 20px; transition: transform 0.2s; }}
        .card:hover {{ transform: translateY(-5px); }}
        .card h2 {{ font-size: 1.4em; margin-top: 0; color: #3498db; }}
        .card h2 a {{ text-decoration: none; color: inherit; }}
        .card p {{ line-height: 1.7; }}
        .source-link {{ display: inline-block; margin-top: 10px; font-weight: bold; color: #3498db; text-decoration: none; }}
        footer {{ text-align: center; margin-top: 40px; color: #7f8c8d; font-size: 0.9em; }}
    </style>
</head>
<body>
    <div class="container">
        <header>
            <h1>ã€Œ{keyword}ã€ã«ã¤ã„ã¦ã®è‡ªå‹•ã¾ã¨ã‚</h1>
        </header>
        <main>
            {cards_html}
        </main>
        <footer>
            <p>ã“ã®ãƒšãƒ¼ã‚¸ã¯Pythonãƒ—ãƒ­ã‚°ãƒ©ãƒ ã«ã‚ˆã£ã¦è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚</p>
        </footer>
    </div>
</body>
</html>
    """
    return html_template

# --- ãƒ¡ã‚¤ãƒ³ã®å‡¦ç† ---
if __name__ == "__main__":
    urls = search_web(SEARCH_KEYWORD, NUM_SITES_TO_CHECK)
    all_site_data = []
    if urls:
        for url in urls:
            content_data = scrape_content(url)
            if content_data:
                all_site_data.append(content_data)
            time.sleep(1)
    if all_site_data:
        final_html = create_html(SEARCH_KEYWORD, all_site_data)
        with open(OUTPUT_FILENAME, "w", encoding="utf-8") as f:
            f.write(final_html)
        print("-" * 50)
        print(f"ğŸ‰ æˆåŠŸï¼ ã€Œ{OUTPUT_FILENAME}ã€ãŒä½œæˆã•ã‚Œã¾ã—ãŸã€‚")
        try:
            from selenium import webdriver
            from selenium.webdriver.chrome.options import Options
            import os
            print("ãƒ‡ãƒãƒƒã‚°ç”¨Chromeã«æ¥ç¶šã—ã¦ã€ãƒšãƒ¼ã‚¸ã‚’é–‹ãã¾ã™...")
            chrome_options = Options()
            chrome_options.add_experimental_option("debuggerAddress", "127.0.0.1:9222")
            driver = webdriver.Chrome(options=chrome_options)
            file_path = os.path.abspath(OUTPUT_FILENAME)
            file_url = 'file:///' + file_path.replace('\\', '/')
            driver.get(file_url)
            print("ãƒšãƒ¼ã‚¸ã‚’é–‹ãã¾ã—ãŸï¼")
        except Exception as e:
            print(f"ãƒ–ãƒ©ã‚¦ã‚¶ã®æ“ä½œã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ‡ãƒãƒƒã‚°ç”¨ChromeãŒèµ·å‹•ã—ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            print(f"ã‚¨ãƒ©ãƒ¼è©³ç´°: {e}")
        print("-" * 50)
    else:
        print("æœ‰åŠ¹ãªæƒ…å ±ã‚’åé›†ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’å¤‰ãˆã¦è©¦ã—ã¦ã¿ã¦ãã ã•ã„ã€‚")